{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 16:37:16.832935: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 16:37:18.229592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from scipy.stats import norm\n",
    "import plotly.graph_objs as go\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108968/307208859.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Days to Expiry'] = X_train['Days to Expiry'].apply(lambda x: 0.5 if x == 0 else x)\n",
      "/tmp/ipykernel_108968/307208859.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Days to Expiry'] = X_test['Days to Expiry'].apply(lambda x: 0.5 if x == 0 else x)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "df_train = pd.read_csv('../Data/train.csv')\n",
    "df_test = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "# Define the features and target\n",
    "features = ['Underlying Price', 'Strike', 'Days to Expiry', 'Underlying Volatility', 'Rate']\n",
    "target = ['Option Price']\n",
    "\n",
    "# Create the training and testing data\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[target]\n",
    "X_test = df_test[features]\n",
    "y_test = df_test[target]\n",
    "# Ensure Days to Expiry is in non-zero days, if zero, set to 0.1\n",
    "X_train['Days to Expiry'] = X_train['Days to Expiry'].apply(lambda x: 0.5 if x == 0 else x)\n",
    "X_test['Days to Expiry'] = X_test['Days to Expiry'].apply(lambda x: 0.5 if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-Scholes Model (parallelized)\n",
    "def parallel_black_scholes(params):\n",
    "    S0, K, T, sigma, r = params\n",
    "    d1 = (np.log(S0 / K) + (r*365 + 0.5 * sigma**2) * T/365) / (sigma * np.sqrt(T/365))\n",
    "    d2 = d1 - sigma * np.sqrt(T/365)\n",
    "    call_price = S0 * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    return call_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 16:37:20.709279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-25 16:37:20.780265: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('Black-Scholes', parallel_black_scholes),\n",
    "    ('MLP', Sequential([\n",
    "        Dense(400, input_dim=5),\n",
    "        LeakyReLU(),\n",
    "        Dense(400, activation='relu'),\n",
    "        Dense(400, activation='relu'),\n",
    "        Dense(400, activation='relu'),\n",
    "        Dense(1),\n",
    "    ]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 4096\n",
    "n_epochs = 10\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "train_metrics = {\n",
    "    'MSE': [],\n",
    "    'MAE': [],\n",
    "    'R2': []\n",
    "}\n",
    "test_metrics = {\n",
    "    'MSE': [],\n",
    "    'MAE': [],\n",
    "    'R2': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Black-Scholes...\n",
      "MSE: 46155.44594536169\n",
      "MAE: 108.27489609318852\n",
      "R2: 0.8853696233641085\n",
      "\n",
      "Training MLP...\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 11s 125ms/step - loss: 841572.6250 - val_loss: 30305.8223\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 26993.4043 - val_loss: 20623.9199\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 23886.3418 - val_loss: 25779.0840\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 10s 122ms/step - loss: 25553.3691 - val_loss: 18074.6699\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 23909.9805 - val_loss: 18028.8867\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 29055.2441 - val_loss: 16849.6250\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 9s 117ms/step - loss: 22979.8984 - val_loss: 21404.6953\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 21674.2832 - val_loss: 15115.8721\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 20019.8379 - val_loss: 13026.2002\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 21159.3281 - val_loss: 26767.3633\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 11s 120ms/step - loss: 20837.2988 - val_loss: 15404.5820\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 9s 112ms/step - loss: 18255.1953 - val_loss: 14822.1602\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 10s 126ms/step - loss: 17886.9785 - val_loss: 11623.4492\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 10s 126ms/step - loss: 17625.6211 - val_loss: 13955.4268\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 10s 128ms/step - loss: 17103.3496 - val_loss: 16059.9365\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 10s 126ms/step - loss: 16800.9941 - val_loss: 10427.4541\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 10s 127ms/step - loss: 16567.0215 - val_loss: 10199.6484\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 10s 127ms/step - loss: 16057.4971 - val_loss: 10361.4102\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 10s 127ms/step - loss: 16089.2754 - val_loss: 12066.0498\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 11s 131ms/step - loss: 15182.0166 - val_loss: 10616.5098\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 12s 131ms/step - loss: 14817.7510 - val_loss: 10174.0518\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 10s 126ms/step - loss: 14691.3027 - val_loss: 10824.5039\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 10s 126ms/step - loss: 14606.5049 - val_loss: 10006.1709\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 10s 127ms/step - loss: 14526.8975 - val_loss: 10957.4326\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 14501.8105 - val_loss: 12517.1445\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 10s 126ms/step - loss: 14387.2891 - val_loss: 9133.9248\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 14338.4209 - val_loss: 10307.9434\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 14244.3535 - val_loss: 10284.8555\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 10s 124ms/step - loss: 14165.7002 - val_loss: 9937.7080\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 10s 123ms/step - loss: 14071.9199 - val_loss: 9960.0820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhairya/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10414/10414 [==============================] - 28s 3ms/step\n",
      "MSE: 13970.899020640327\n",
      "MAE: 70.55465908010652\n",
      "R2: 0.9653022653367095\n",
      "\n",
      "{'MSE': [46155.44594536169, 13970.899020640327], 'MAE': [108.27489609318852, 70.55465908010652], 'R2': [0.8853696233641085, 0.9653022653367095]}\n"
     ]
    }
   ],
   "source": [
    "for i, (name, model) in enumerate(models):\n",
    "    print(f'Training {name}...')\n",
    "    if name == 'Black-Scholes':\n",
    "        pool = multiprocessing.Pool()\n",
    "        y_pred = pool.map(parallel_black_scholes, X_train.values)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        # If model is already trained, load it\n",
    "        if os.path.exists(f'../Models/{name}.h5'):\n",
    "            model = load_model(f'../Models/{name}.h5')\n",
    "            models[i] = (name,model)\n",
    "        else:\n",
    "            full_history = None\n",
    "            for lr in learning_rates:\n",
    "                model.compile(loss='mse', optimizer=Adam(learning_rate=lr))\n",
    "                history = model.fit(X_train, y_train, \n",
    "                            batch_size=n_batch, epochs=n_epochs, \n",
    "                            validation_split = 0.01,\n",
    "                            callbacks=[TensorBoard()],\n",
    "                            verbose=1)\n",
    "                # Concatenate the history\n",
    "                if full_history is None:\n",
    "                    full_history = history.history\n",
    "                else:\n",
    "                    for key in history.history:\n",
    "                        full_history[key] += history.history[key]\n",
    "            history = full_history\n",
    "            # Save the model\n",
    "            model.save(f'../Models/{name}.h5')\n",
    "            # Plot the training history\n",
    "            fig = go.Figure(data=[\n",
    "                go.Scatter(name='Training', x=np.arange(n_epochs*len(learning_rates)), y=history['loss'])\n",
    "            ])\n",
    "            fig.update_layout(title=f'{name} Training History', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "            #Save the plot\n",
    "            fig.write_image(f'../Images/{name}_training_history.png')\n",
    "        y_pred = model.predict(X_train)\n",
    "    print(f'MSE: {mean_squared_error(y_train, y_pred)}')\n",
    "    print(f'MAE: {mean_absolute_error(y_train, y_pred)}')\n",
    "    print(f'R2: {r2_score(y_train, y_pred)}')\n",
    "    print()\n",
    "    train_metrics['MSE'].append(mean_squared_error(y_train, y_pred))\n",
    "    train_metrics['MAE'].append(mean_absolute_error(y_train, y_pred))\n",
    "    train_metrics['R2'].append(r2_score(y_train, y_pred))\n",
    "\n",
    "print(train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Black-Scholes...\n",
      "MSE: 32299.474557791524\n",
      "MAE: 90.3169194664287\n",
      "R2: 0.9283768050161211\n",
      "\n",
      "Testing MLP...\n",
      "1733/1733 [==============================] - 7s 4ms/step\n",
      "MSE: 14534.982809485924\n",
      "MAE: 88.63554024520005\n",
      "R2: 0.9677690760576162\n",
      "\n",
      "{'MSE': [32299.474557791524, 14534.982809485924], 'MAE': [90.3169194664287, 88.63554024520005], 'R2': [0.9283768050161211, 0.9677690760576162]}\n"
     ]
    }
   ],
   "source": [
    "# Test the models\n",
    "for name, model in models:\n",
    "    print(f'Testing {name}...')\n",
    "    if name == 'Black-Scholes':\n",
    "        pool = multiprocessing.Pool()\n",
    "        y_pred = pool.map(parallel_black_scholes, X_test.values)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
    "    print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "    print(f'R2: {r2_score(y_test, y_pred)}')\n",
    "    print()\n",
    "    test_metrics['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "    test_metrics['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    test_metrics['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results 3 plots for MSE, MAE and R-squared comparing Testing and Training\n",
    "for metric in train_metrics:\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name='Training', x=[name for name, _ in models], y=train_metrics[metric], text=[round(m,2) for m in train_metrics[metric]], textposition='auto'),\n",
    "        go.Bar(name='Testing', x=[name for name, _ in models], y=test_metrics[metric], text=[round(m,2) for m in test_metrics[metric]], textposition='auto')\n",
    "    ])\n",
    "    fig.update_layout(title=f'{metric} Comparison', xaxis_title='Model', yaxis_title=metric)\n",
    "    #Save the plot\n",
    "    fig.write_image(f'../Images/{metric}_comparison.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
